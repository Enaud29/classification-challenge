# classification-challenge
## Duane Anglin

![Screenshot 2024-06-12 at 9 50 18â€¯AM](https://github.com/Enaud29/CryptoClustering/assets/161158238/a0b64168-fe0c-4677-9925-98a031b3f396)

### Summary
After loading in the data I predicted that if the data is complex,Random Forest Classifier will perform better than Logistic Regression. If the data is simple, Logistic Regression will perform better than Random Forest Classifier. I then create a y label which is extracted from the spam column and a X label which is the remaining columns. 0 in the spam column means the message is real 1 means the message is spam. I split the data into training and testing sets. Next I fit the model using train_test_split. Next I scaled the data using StandardScaler. Finally I used Logistic Regression and Random orest Classifier to make predictions. In the end the Random Forest Classifier performed better because it had a higher accuracy score.




#### References
Chat GPT, Kalvin Anglin, Solutions examples from class.
